{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "269c8dc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      ID             Name  Duration  Rating     Genre\n",
      "0    1.0        Inception     148.0     8.8    Sci-Fi\n",
      "1    2.0    The Godfather     175.0     9.2     Crime\n",
      "2    3.0     Interstellar     100.0     8.6    Sci-Fi\n",
      "4    4.0         Parasite     132.0   100.0  Thriller\n",
      "5    5.0  The Dark Knight     152.0     9.0       100\n",
      "6    6.0              100     120.0     7.5     Drama\n",
      "7    7.0     Forrest Gump     142.0     8.8    Comedy\n",
      "8    8.0           Avatar     100.0     7.8    Sci-Fi\n",
      "9    9.0        Gladiator     155.0   100.0    Action\n",
      "10  10.0          Titanic     195.0     7.9       100\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from io import StringIO\n",
    "\n",
    "data = \"\"\"ID,Name,Duration,Rating,Genre\n",
    "1,Inception,148,8.8,Sci-Fi\n",
    "\n",
    "2,The Godfather,175,9.2,Crime\n",
    "3,Interstellar,,8.6,Sci-Fi\n",
    ",,,,\n",
    "4,Parasite,132,,Thriller\n",
    "5,The Dark Knight,152,9.0,\n",
    "6,,120,7.5,Drama\n",
    "\n",
    "7,Forrest Gump,142,8.8,Comedy\n",
    "8,Avatar,,7.8,Sci-Fi\n",
    "9,Gladiator,155,,Action\n",
    "10,Titanic,195,7.9,\n",
    "\"\"\"\n",
    "\n",
    "df = pd.read_csv(StringIO(data))\n",
    "\n",
    "# Treat empty strings as NaN\n",
    "df.replace(r'^\\s*$', pd.NA, regex=True, inplace=True)\n",
    "\n",
    "# Drop fully empty rows\n",
    "df.dropna(how='all', inplace=True)\n",
    "\n",
    "# Fill missing values with 100\n",
    "df.fillna(100, inplace=True)\n",
    "\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b2112318",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned dataset:\n",
      "                     ID          Name  Duration  Rating   Genre\n",
      "2                    3  Interstellar     100.0     8.6  Sci-Fi\n",
      "6                    6           100     120.0     7.5   Drama\n",
      "8                    8        Avatar     100.0     7.8  Sci-Fi\n",
      "11  # duplicates below           100     100.0   100.0     100\n",
      "12                   3  Interstellar     100.0     8.6  Sci-Fi\n",
      "13                   6           100     120.0     7.5   Drama \n",
      "\n",
      "Any duplicates?: True\n",
      "Number of duplicate rows: 2\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from io import StringIO\n",
    "\n",
    "data = \"\"\"ID,Name,Duration,Rating,Genre\n",
    "1,Inception,148,8.8,Sci-Fi\n",
    "\n",
    "2,The Godfather,175,9.2,Crime\n",
    "3,Interstellar,,8.6,Sci-Fi\n",
    ",,,,\n",
    "4,Parasite,132,,Thriller\n",
    "5,The Dark Knight,152,9.0,\n",
    "6,,120,7.5,Drama\n",
    "\n",
    "7,Forrest Gump,142,8.8,Comedy\n",
    "8,Avatar,,7.8,Sci-Fi\n",
    "9,Gladiator,155,,Action\n",
    "10,Titanic,195,7.9,\n",
    "\n",
    "# duplicates below\n",
    "3,Interstellar,,8.6,Sci-Fi\n",
    "6,,120,7.5,Drama\n",
    "9,Gladiator,155,,Action\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(StringIO(data))\n",
    "\n",
    "# Replace empty strings with NaN\n",
    "df.replace(r'^\\s*$', pd.NA, regex=True, inplace=True)\n",
    "\n",
    "# Drop completely empty rows\n",
    "df.dropna(how='all', inplace=True)\n",
    "\n",
    "# Fill missing values with 100\n",
    "df.fillna(100, inplace=True)\n",
    "\n",
    "# Drop rows where Duration > 120\n",
    "df = df[df[\"Duration\"].astype(float) <= 120]\n",
    "\n",
    "# Check duplicates\n",
    "duplicates = df.duplicated().any()\n",
    "duplicate_count = df.duplicated().sum()\n",
    "\n",
    "print(\"Cleaned dataset:\\n\", df, \"\\n\")\n",
    "print(\"Any duplicates?:\", duplicates)\n",
    "print(\"Number of duplicate rows:\", duplicate_count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fe2b5149",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   support                         itemsets\n",
      "0      0.7                        (Charger)\n",
      "1      0.9                     (Headphones)\n",
      "2      0.8                         (Laptop)\n",
      "3      0.5                      (USB Drive)\n",
      "4      0.6            (Charger, Headphones)\n",
      "5      0.5                (Charger, Laptop)\n",
      "6      0.7             (Laptop, Headphones)\n",
      "7      0.5          (Headphones, USB Drive)\n",
      "8      0.5              (Laptop, USB Drive)\n",
      "9      0.5  (Laptop, Headphones, USB Drive)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from mlxtend.preprocessing import TransactionEncoder\n",
    "from mlxtend.frequent_patterns import apriori\n",
    "\n",
    "# Sample transactional data as list of lists\n",
    "transactions = [\n",
    "    ['Laptop', 'Mouse', 'Keyboard', 'USB Drive', 'Headphones'],\n",
    "    ['Phone', 'Charger', 'Headphones', 'Power Bank', 'Cover'],\n",
    "    ['Tablet', 'Stylus', 'Cover', 'Charger', 'Headphones'],\n",
    "    ['Laptop', 'Headphones', 'USB Drive', 'Keyboard', 'Mouse'],\n",
    "    ['Phone', 'Laptop', 'Charger', 'Headphones', 'USB Drive'],\n",
    "    ['Camera', 'Tripod', 'SD Card', 'Laptop', 'Headphones'],\n",
    "    ['Phone', 'Cover', 'Headphones', 'Power Bank', 'Charger', 'Laptop'],\n",
    "    ['Tablet', 'Charger', 'Stylus', 'Cover', 'Laptop', 'Mouse'],\n",
    "    ['Laptop', 'Mouse', 'Keyboard', 'USB Drive', 'Headphones', 'Charger'],\n",
    "    ['Camera', 'Laptop', 'Headphones', 'Phone', 'Charger', 'USB Drive']\n",
    "]\n",
    "\n",
    "# Convert transactions to one-hot encoded DataFrame\n",
    "te = TransactionEncoder()\n",
    "te_ary = te.fit(transactions).transform(transactions)\n",
    "df = pd.DataFrame(te_ary, columns=te.columns_)\n",
    "\n",
    "# Apply Apriori algorithm with minimum support = 0.5\n",
    "frequent_itemsets = apriori(df, min_support=0.5, use_colnames=True)\n",
    "\n",
    "print(frequent_itemsets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7a75b37e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   support                         itemsets\n",
      "0      0.9                     (Headphones)\n",
      "1      0.8                         (Laptop)\n",
      "2      0.5                      (USB Drive)\n",
      "3      0.7                        (Charger)\n",
      "4      0.7             (Laptop, Headphones)\n",
      "5      0.5              (Laptop, USB Drive)\n",
      "6      0.5          (Headphones, USB Drive)\n",
      "7      0.5  (Headphones, Laptop, USB Drive)\n",
      "8      0.6            (Charger, Headphones)\n",
      "9      0.5                (Charger, Laptop)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from mlxtend.preprocessing import TransactionEncoder\n",
    "from mlxtend.frequent_patterns import fpgrowth\n",
    "\n",
    "# Transform transactions into one-hot encoded DataFrame\n",
    "transactions = [\n",
    "    ['Laptop', 'Mouse', 'Keyboard', 'USB Drive', 'Headphones'],\n",
    "    ['Phone', 'Charger', 'Headphones', 'Power Bank', 'Cover'],\n",
    "    ['Tablet', 'Stylus', 'Cover', 'Charger', 'Headphones'],\n",
    "    ['Laptop', 'Headphones', 'USB Drive', 'Keyboard', 'Mouse'],\n",
    "    ['Phone', 'Laptop', 'Charger', 'Headphones', 'USB Drive'],\n",
    "    ['Camera', 'Tripod', 'SD Card', 'Laptop', 'Headphones'],\n",
    "    ['Phone', 'Cover', 'Headphones', 'Power Bank', 'Charger', 'Laptop'],\n",
    "    ['Tablet', 'Charger', 'Stylus', 'Cover', 'Laptop', 'Mouse'],\n",
    "    ['Laptop', 'Mouse', 'Keyboard', 'USB Drive', 'Headphones', 'Charger'],\n",
    "    ['Camera', 'Laptop', 'Headphones', 'Phone', 'Charger', 'USB Drive']\n",
    "]\n",
    "\n",
    "te = TransactionEncoder()\n",
    "te_ary = te.fit(transactions).transform(transactions)\n",
    "df = pd.DataFrame(te_ary, columns=te.columns_)\n",
    "\n",
    "# Apply FP-Growth algorithm with minimum support 0.5\n",
    "frequent_itemsets = fpgrowth(df, min_support=0.5, use_colnames=True)\n",
    "\n",
    "print(frequent_itemsets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "dae7f6ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.825\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.30      0.46        10\n",
      "           1       1.00      1.00      1.00         8\n",
      "           2       0.63      1.00      0.77        12\n",
      "           3       1.00      1.00      1.00        10\n",
      "\n",
      "    accuracy                           0.82        40\n",
      "   macro avg       0.91      0.82      0.81        40\n",
      "weighted avg       0.89      0.82      0.80        40\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# Load and clean dataset\n",
    "df = pd.read_csv('gender.csv')\n",
    "df.columns = df.columns.str.strip()\n",
    "df = df.loc[:, ~df.columns.str.contains('^Unnamed')]\n",
    "df = df.dropna()\n",
    "\n",
    "# Use all columns except 'Gender' as features, 'Gender' as target\n",
    "X = df.drop('Gender', axis=1)\n",
    "y = df['Gender']\n",
    "\n",
    "# Encode categorical features and target\n",
    "for col in X.columns:\n",
    "    if X[col].dtype == 'object':\n",
    "        X[col] = pd.factorize(X[col])[0]\n",
    "if y.dtype == 'object':\n",
    "    y = pd.factorize(y)[0]\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Train SVM (linear kernel)\n",
    "clf = svm.SVC(kernel='linear')\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict and evaluate\n",
    "y_pred = clf.predict(X_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "2c769e99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.50      0.50         2\n",
      "           1       0.67      0.67      0.67         3\n",
      "\n",
      "    accuracy                           0.60         5\n",
      "   macro avg       0.58      0.58      0.58         5\n",
      "weighted avg       0.60      0.60      0.60         5\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Lab 06: Predict the output using Bayesian Network (Naive Bayes Example)\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Example synthetic dataset\n",
    "data = {\n",
    "    'Weather': ['Sunny', 'Sunny', 'Overcast', 'Rain', 'Rain', 'Rain', 'Overcast', 'Sunny', 'Sunny', 'Rain', 'Sunny', 'Overcast', 'Overcast', 'Rain'],\n",
    "    'Temperature': ['Hot', 'Hot', 'Hot', 'Mild', 'Cool', 'Cool', 'Cool', 'Mild', 'Cool', 'Mild', 'Mild', 'Mild', 'Hot', 'Mild'],\n",
    "    'Humidity': ['High', 'High', 'High', 'High', 'Normal', 'Normal', 'Normal', 'High', 'Normal', 'Normal', 'Normal', 'High', 'Normal', 'High'],\n",
    "    'Windy': ['False', 'True', 'False', 'False', 'False', 'True', 'True', 'False', 'False', 'False', 'True', 'True', 'False', 'True'],\n",
    "    'Play': ['No', 'No', 'Yes', 'Yes', 'Yes', 'No', 'Yes', 'No', 'Yes', 'Yes', 'Yes', 'Yes', 'Yes', 'No']\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Encode categorical features\n",
    "for col in df.columns:\n",
    "    if df[col].dtype == 'object':\n",
    "        df[col] = pd.factorize(df[col])[0]\n",
    "\n",
    "X = df.drop('Play', axis=1)\n",
    "y = df['Play']\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Train Naive Bayes classifier (Bayesian Network)\n",
    "model = GaussianNB()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict and evaluate\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f718897",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
